{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c98c967-2beb-4c39-81bc-1e41040f3f85",
   "metadata": {},
   "source": [
    "# Cough Detection Feature Extraction\n",
    "\n",
    "This notebook reproduces eature extraction for classical ML pipeline from the research paper for cough detection using multimodal biosignals.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Extract dataset features for three modality configurations:\n",
    "1. **IMU-only**: 40 handcrafted features from accelerometer and gyroscope\n",
    "2. **Audio-only**: 65 features from outer microphone (MFCC + spectral + time-domain)\n",
    "3. **Multimodal**: Combined 105 features (Audio + IMU)\n",
    "\n",
    "## Method\n",
    "\n",
    "- **Window size**: 0.4 seconds (6400 audio samples @ 16kHz, 40 IMU samples @ 100Hz)\n",
    "- **Data augmentation**: Random temporal shifts (aug_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, signal\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from helpers import *\n",
    "from dataset_gen import *\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ebe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Constants from paper\n",
    "WINDOW_LEN = 0.4  # 0.4 second windows\n",
    "AUG_FACTOR = 2    # Data augmentation factor\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Window length: {WINDOW_LEN}s\")\n",
    "print(f\"  Expected audio samples: {int(WINDOW_LEN * FS_AUDIO)}\")\n",
    "print(f\"  Expected IMU samples: {int(WINDOW_LEN * FS_IMU)}\")\n",
    "print(f\"  Augmentation factor: {AUG_FACTOR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc7188",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions\n",
    "\n",
    "### Audio Features (65 total)\n",
    "\n",
    "1. **MFCC (52)**: 13 coefficients × 4 statistics (mean, std, min, max)\n",
    "2. **Spectral (10)**: Centroid, rolloff, bandwidth, flatness, contrast, PSD features, spectral spread/skewness/kurtosis\n",
    "3. **Time-domain (3)**: Zero-crossing rate, RMS energy, crest factor\n",
    "\n",
    "### IMU Features (40 total)\n",
    "\n",
    "For 8 signals (3 accel + accel_L2 + 3 gyro + gyro_L2):\n",
    "- Line length, zero-crossing rate, kurtosis, crest factor, RMS = 5 features per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(audio_window, fs=16000):\n",
    "    \"\"\"\n",
    "    Extract 65 audio features from single window\n",
    "    \n",
    "    Args:\n",
    "        audio_window: 1D array of audio samples\n",
    "        fs: Sampling frequency (16000 Hz)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 65 features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # MFCC features (52)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_window, sr=fs, n_mfcc=13)\n",
    "    for coef in mfccs:\n",
    "        features.extend([np.mean(coef), np.std(coef), np.min(coef), np.max(coef)])\n",
    "    \n",
    "    # Spectral features (10)\n",
    "    features.append(np.mean(librosa.feature.spectral_centroid(y=audio_window, sr=fs)))\n",
    "    features.append(np.mean(librosa.feature.spectral_rolloff(y=audio_window, sr=fs)))\n",
    "    features.append(np.mean(librosa.feature.spectral_bandwidth(y=audio_window, sr=fs)))\n",
    "    features.append(np.mean(librosa.feature.spectral_flatness(y=audio_window)))\n",
    "    features.append(np.mean(librosa.feature.spectral_contrast(y=audio_window, sr=fs)))\n",
    "    \n",
    "    # PSD-based features\n",
    "    f, psd = signal.welch(audio_window, fs=fs)\n",
    "    features.append(np.sum(psd))  # Total power\n",
    "    dom_freq_idx = np.argmax(psd)\n",
    "    features.append(f[dom_freq_idx])  # Dominant frequency\n",
    "    \n",
    "    # Spectral spread, skewness, kurtosis\n",
    "    psd_norm = psd / (np.sum(psd) + 1e-10)\n",
    "    spectral_mean = np.sum(f * psd_norm)\n",
    "    features.append(np.sqrt(np.sum(((f - spectral_mean)**2) * psd_norm)))  # Spread\n",
    "    features.append(np.sum(((f - spectral_mean)**3) * psd_norm))  # Skewness\n",
    "    features.append(np.sum(((f - spectral_mean)**4) * psd_norm))  # Kurtosis\n",
    "    \n",
    "    # Time-domain features (3)\n",
    "    features.append(librosa.feature.zero_crossing_rate(audio_window)[0].mean())\n",
    "    rms = np.sqrt(np.mean(audio_window**2))\n",
    "    features.append(rms)\n",
    "    features.append(np.max(np.abs(audio_window)) / (rms + 1e-10))  # Crest factor\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Test on random data\n",
    "test_audio = np.random.randn(6400)\n",
    "test_features = extract_audio_features(test_audio)\n",
    "print(f\"✓ Audio feature extractor: {len(test_features)} features\")\n",
    "assert len(test_features) == 65, f\"Expected 65 features, got {len(test_features)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imu_features(imu_window):\n",
    "    \"\"\"\n",
    "    Extract 40 IMU features\n",
    "    \n",
    "    Args:\n",
    "        imu_window: (40, 6) array - [Accel_x, Accel_y, Accel_z, Gyro_Y, Gyro_P, Gyro_R]\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 40 features (8 signals × 5 features)\n",
    "    \"\"\"\n",
    "    # Subtract mean per channel (paper requirement)\n",
    "    imu_centered = imu_window - np.mean(imu_window, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute L2 norms\n",
    "    accel_l2 = np.linalg.norm(imu_centered[:, 0:3], axis=1)\n",
    "    gyro_l2 = np.linalg.norm(imu_centered[:, 3:6], axis=1)\n",
    "    \n",
    "    # Stack all 8 signals\n",
    "    signals = np.column_stack([\n",
    "        imu_centered[:, 0], imu_centered[:, 1], imu_centered[:, 2], accel_l2,\n",
    "        imu_centered[:, 3], imu_centered[:, 4], imu_centered[:, 5], gyro_l2\n",
    "    ])\n",
    "    \n",
    "    features = []\n",
    "    for i in range(8):\n",
    "        sig = signals[:, i]\n",
    "        \n",
    "        # Line length\n",
    "        features.append(np.sum(np.abs(np.diff(sig))))\n",
    "        \n",
    "        # Zero crossing rate\n",
    "        features.append(np.sum(np.diff(np.sign(sig)) != 0) / len(sig))\n",
    "        \n",
    "        # Kurtosis\n",
    "        features.append(stats.kurtosis(sig))\n",
    "        \n",
    "        # Crest factor\n",
    "        rms = np.sqrt(np.mean(sig**2))\n",
    "        features.append(np.max(np.abs(sig)) / (rms + 1e-10))\n",
    "        \n",
    "        # RMS power\n",
    "        features.append(rms)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Test on random data\n",
    "test_imu = np.random.randn(40, 6)\n",
    "test_features = extract_imu_features(test_imu)\n",
    "print(f\"✓ IMU feature extractor: {len(test_features)} features\")\n",
    "assert len(test_features) == 40, f\"Expected 40 features, got {len(test_features)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_dataset(audio_data, imu_data, modality='all'):\n",
    "    \"\"\"\n",
    "    Extract features for entire dataset\n",
    "    \n",
    "    Args:\n",
    "        audio_data: (N, 6400, 2) - [outer_mic, body_mic]\n",
    "        imu_data: (N, 40, 6)\n",
    "        modality: 'imu_only', 'audio_only', or 'all'\n",
    "    \n",
    "    Returns:\n",
    "        X: (N, n_features) feature matrix\n",
    "    \"\"\"\n",
    "    N = audio_data.shape[0]\n",
    "    features_list = []\n",
    "    \n",
    "    for i in tqdm(range(N), desc=f\"Extracting {modality} features\"):\n",
    "        sample_features = []\n",
    "        \n",
    "        if modality in ['audio_only', 'all']:\n",
    "            # Use outer microphone (index 0)\n",
    "            audio_outer = audio_data[i, :, 0]\n",
    "            sample_features.extend(extract_audio_features(audio_outer))\n",
    "        \n",
    "        if modality in ['imu_only', 'all']:\n",
    "            imu_window = imu_data[i, :, :]\n",
    "            sample_features.extend(extract_imu_features(imu_window))\n",
    "        \n",
    "        features_list.append(sample_features)\n",
    "    \n",
    "    X = np.array(features_list)\n",
    "    \n",
    "    # Handle NaN/Inf values\n",
    "    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "        print(f\"Warning: Replacing {np.sum(np.isnan(X))} NaN and {np.sum(np.isinf(X))} Inf values\")\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return X\n",
    "\n",
    "print(\"✓ Batch feature extraction function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90a440",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load raw windowed data from all 15 subjects using `get_samples_for_subject()` from `dataset_gen.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate dataset folder\n",
    "kaggle_dataset_dir = '/kaggle/input/edge-ai-cough-count'\n",
    "base_dir = kaggle_dataset_dir if os.path.exists(kaggle_dataset_dir) else \"..\"\n",
    "data_folder = base_dir + '/public_dataset/'\n",
    "\n",
    "# Check if exists, otherwise try alternative path\n",
    "if not os.path.exists(data_folder):\n",
    "    data_folder = '../data/public_dataset/'\n",
    "    if not os.path.exists(data_folder):\n",
    "        raise FileNotFoundError(\n",
    "            \"Cannot find public_dataset/. Please download from: \"\n",
    "            \"https://zenodo.org/record/7562332\"\n",
    "        )\n",
    "\n",
    "# Get list of subject IDs\n",
    "subject_ids = [d for d in os.listdir(data_folder) \n",
    "               if os.path.isdir(os.path.join(data_folder, d))]\n",
    "subject_ids = sorted(subject_ids)\n",
    "\n",
    "print(f\"✓ Found {len(subject_ids)} subjects: {subject_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw windowed data from all subjects\n",
    "all_audio = []\n",
    "all_imu = []\n",
    "all_labels = []\n",
    "all_subjects = []\n",
    "\n",
    "print(\"Loading dataset (this may take a few minutes)...\\n\")\n",
    "\n",
    "for subj_id in tqdm(subject_ids, desc=\"Loading subjects\"):\n",
    "    try:\n",
    "        audio, imu, labels, n_coughs = get_samples_for_subject(\n",
    "            data_folder, subj_id,\n",
    "            window_len=WINDOW_LEN,\n",
    "            aug_factor=AUG_FACTOR\n",
    "        )\n",
    "        \n",
    "        all_audio.append(audio)\n",
    "        all_imu.append(imu)\n",
    "        all_labels.append(labels)\n",
    "        all_subjects.extend([subj_id] * len(labels))\n",
    "        \n",
    "        print(f\"  {subj_id}: {n_coughs} coughs → {len(labels)} windows \"\n",
    "              f\"({np.sum(labels==1)} cough, {np.sum(labels==0)} non-cough)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {subj_id}: Error - {e}\")\n",
    "        continue\n",
    "\n",
    "# Concatenate all subjects\n",
    "audio_data = np.concatenate(all_audio, axis=0)\n",
    "imu_data = np.concatenate(all_imu, axis=0)\n",
    "labels = np.concatenate(all_labels, axis=0)\n",
    "subjects = np.array(all_subjects)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Total dataset:\")\n",
    "print(f\"  Audio shape: {audio_data.shape}\")\n",
    "print(f\"  IMU shape: {imu_data.shape}\")\n",
    "print(f\"  Labels: {len(labels)} ({np.sum(labels==1)} coughs, {np.sum(labels==0)} non-coughs)\")\n",
    "print(f\"  Unique subjects: {len(np.unique(subjects))}\")\n",
    "print(f\"  Class balance: {np.sum(labels==1)/len(labels)*100:.1f}% coughs\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert audio_data.shape[1] == 6400, f\"Expected 6400 audio samples, got {audio_data.shape[1]}\"\n",
    "assert imu_data.shape[1] == 40, f\"Expected 40 IMU samples, got {imu_data.shape[1]}\"\n",
    "assert len(np.unique(subjects)) == 15, f\"Expected 15 subjects, got {len(np.unique(subjects))}\"\n",
    "\n",
    "# Visualize one cough sample\n",
    "idx = np.where(labels == 1)[0][0]\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "axes[0].plot(audio_data[idx, :, 0], linewidth=0.5)\n",
    "axes[0].set_title(f\"Sample Cough - Outer Microphone (Subject {subjects[idx]})\")\n",
    "axes[0].set_xlabel(\"Sample Index\")\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(-imu_data[idx, :, 2], linewidth=1)\n",
    "axes[1].set_title(\"Accelerometer Z (negated)\")\n",
    "axes[1].set_xlabel(\"Sample Index\")\n",
    "axes[1].set_ylabel(\"Acceleration\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Data loaded and verified successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9ac80",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Extract handcrafted features for all three modalities:\n",
    "1. IMU-only: 40 features\n",
    "2. Audio-only: 65 features\n",
    "3. Multimodal: 105 features\n",
    "\n",
    "**Note**: This may take 10-20 minutes depending on hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "print(\"Extracting features for all modalities...\\n\")\n",
    "\n",
    "N = audio_data.shape[0]\n",
    "n_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "# Configure parallelization based on available cores\n",
    "if n_cpus >= 8:\n",
    "    n_jobs = 8\n",
    "    n_jobs = 8\n",
    "    blas_threads = 2\n",
    "else:\n",
    "    # Run with all CPUs, but without blas threads\n",
    "    n_jobs = n_cpus\n",
    "    blas_threads = 1\n",
    "\n",
    "# Limit BLAS threading to prevent oversubscription\n",
    "os.environ['OMP_NUM_THREADS'] = str(blas_threads)\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = str(blas_threads)\n",
    "os.environ['MKL_NUM_THREADS'] = str(blas_threads)\n",
    "\n",
    "print(f\"Hardware: {n_cpus} CPU cores detected\")\n",
    "print(f\"Configuration: {n_jobs} workers × {blas_threads} BLAS threads = {n_jobs * blas_threads} total\\n\")\n",
    "\n",
    "# ===================================================================\n",
    "# Step 1/2: Extract audio features (65 features from outer mic)\n",
    "# ===================================================================\n",
    "print(\"Step 1/2: Extracting audio features...\")\n",
    "audio_features_list = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "    delayed(extract_audio_features)(audio_data[i, :, 0])\n",
    "    for i in tqdm(range(N), desc=\"Audio features\")\n",
    ")\n",
    "X_audio = np.array(audio_features_list)\n",
    "\n",
    "# Handle NaN/Inf in audio features\n",
    "if np.any(np.isnan(X_audio)) or np.any(np.isinf(X_audio)):\n",
    "    print(f\"  Warning: Replacing {np.sum(np.isnan(X_audio))} NaN and {np.sum(np.isinf(X_audio))} Inf values in audio\")\n",
    "    X_audio = np.nan_to_num(X_audio, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# ===================================================================\n",
    "# Step 2/2: Extract IMU features (40 features)\n",
    "# ===================================================================\n",
    "print(\"\\nStep 2/2: Extracting IMU features...\")\n",
    "imu_features_list = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "    delayed(extract_imu_features)(imu_data[i, :, :])\n",
    "    for i in tqdm(range(N), desc=\"IMU features\")\n",
    ")\n",
    "X_imu = np.array(imu_features_list)\n",
    "\n",
    "# Handle NaN/Inf in IMU features\n",
    "if np.any(np.isnan(X_imu)) or np.any(np.isinf(X_imu)):\n",
    "    print(f\"  Warning: Replacing {np.sum(np.isnan(X_imu))} NaN and {np.sum(np.isinf(X_imu))} Inf values in IMU\")\n",
    "    X_imu = np.nan_to_num(X_imu, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# ===================================================================\n",
    "# Combine for multimodal (65 audio + 40 IMU = 105 features)\n",
    "# ===================================================================\n",
    "X_all = np.concatenate([X_audio, X_imu], axis=1)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Feature extraction complete:\")\n",
    "print(f\"  Audio-only: {X_audio.shape} (65 features)\")\n",
    "print(f\"  IMU-only: {X_imu.shape} (40 features)\")\n",
    "print(f\"  Multimodal: {X_all.shape} (105 features)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to avoid re-extraction\n",
    "save_path = 'extracted_features.npz'\n",
    "np.savez(\n",
    "    save_path,\n",
    "    X_imu=X_imu, \n",
    "    X_audio=X_audio, \n",
    "    X_all=X_all,\n",
    "    labels=labels, \n",
    "    subjects=subjects\n",
    ")\n",
    "print(f\"✓ Features saved to {save_path}\")\n",
    "print(f\"  To load: data = np.load('{save_path}')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
